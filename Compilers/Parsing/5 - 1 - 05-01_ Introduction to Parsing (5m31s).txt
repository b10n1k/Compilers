
In this video, we're going to transition
from lexical analysis to parsing and talk
a little bit about the relationship
between those two compiler phases. We've
already talked about regular languages and
it's worth mentioning that these are the
weakest formal languages that are widely
used. But they have, of course, many
applications, some of which we saw in
previous videos. The difficulty with
regular languages is that a lot of
languages are simply not regular. And
there's some pretty important languages
that can't be expressed using regular
expressions or finite automata. So let's
consider this language which is the set of
all balanced parentheses. So some elements
of this language would be at the string
one open-paren, one close-paren, two
open-parens, two close-parens, three
open-parens, three close-parens and so on.
And, you can imagine that this is actually
something that's fairly representative of
lots of programming language construct. So
for example, any kind of nested arithmetic
expression would fit into this class but
also things like nested if and else's will
have this category, this characteristic.
And here with the nested [inaudible] it's
just the f statement, the functions like
an open-paren. Not every languages like
cool which has the explicit closing fee as
well but they're implicit in many
languages and so there are lots of nesting
structure in programming languages
constructs and those cannot be handled by
regular expressions. So this raises the
question of what the regular languages can
express. And, why they aren't sufficient
for recognizing arbitrary nesting
structure. So we can illustrate the
limitations of regular languages and
Finite Automaton by looking a simple two
state machine. So let's consider this
machine. We have one we have start state
and then the other state is the accepting
state. And, we'll have this machine. Just
be a machine that we've already seen
actually and it'll recognize strings with
odd numbers of 1's. So if we see a one and
we're in the start state, we move. We now
see an odd number of 1's. We move to the
accepting state and we stay there until we
see another one. In which case, we've seen
even number of 1's and then we're in the
start state. So whenever we see an odd
number of 1's, we're in the final state.
Whenever we see an even number of 1's,
we're in the start state. And if we feed
this a fairly long string of 1's, let's,
let's select only seven 1's in it. Then
what's it going to do is going to go back
and forth and back and forth between these
states. It's gonna wind up in the final
state when it gets to the last one so
it'll accept but notice that it doesn't
know how many times it's been to that
final state. It doesn't remember the
length of the string; it doesn't have any
way of counting how many characters the
string had in it. And in fact, all I can
count here is the parity. So in general
Finite Automata can really only express
things where you can count modulus on k.
So they can count mod k for some k where k
is the number of states in the machine.
And so, you know if I have pre-test the
machine, I can keep track of whether the
string length is divisible by three or
some other similar property but I can't do
things like count to an arbitrary i so if
I need to recognize a language that
requires counting arbitrarily high like
recognizing all strings of balance
parentheses, we can't do that with the
finite set of states. So what does a
parser do, it takes the sequence of tokens
as input from the lexer and it produces a
parse tree of the program. And for example
in cool, here's an input expression that
is input to the lexical analyzer. The
lexical analyzer produces this sequence of
tokens as its output. That's the input to
the parser. Then the parser produces this
parse tree where the nesting structure has
been made explicit. So, we have the, if
and else and then the three components:
the predicate, the then branch and the
else branch of the, if To summarize, the
lexer takes a string of character as input
and produces a string of tokens as output.
That string of tok ens is the input to the
parser which takes a string of tokens and
produces a Parse Tree of the program. And
it's worth mentioning a couple of thing
here. First of all, sometimes the Parse
Tree is only implicit. So the, a compiler
may never actually build the full Parse
Tree. We'll talk more about that later.
Many compilers do build an explicit parse
tree but many do not. The other thing
that's worth mentioning is that there are
compilers that do combine these two phases
into one where everything is done by the
parser. So, the parsing technology is
generally powerful enough to express
lexical analysis in addition to parsing.
But most compilers still divide up the
work this way because regular expressions
are such a good match for lexical analysis
and then the parsing is handled
separately.
